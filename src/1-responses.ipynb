{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import spotipy\n",
    "import time\n",
    "from spotipy.oauth2 import SpotifyClientCredentials #To access authorised Spotify data4\n",
    "import pandas as pd\n",
    "import random\n",
    "import credentials as cred\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token  = cred.spotifyToken()\n",
    "headers = {\"Authorization\":f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"https://api.spotify.com/v1/playlists/\"\n",
    "playlist_link = 'https://open.spotify.com/playlist/37i9dQZF1DXcBWIGoYBM5M?si=b705194596334305'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = cred.playlist_query ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = cred.playlist_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_items_dict = cred.track_items ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_items_dict = cred.track_audio_features ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for \"Die For You - Remix\" by The Weeknd...\n",
      "Done.\n",
      "Searching for \"Flowers\" by Miley Cyrus...\n",
      "Done.\n",
      "Searching for \"Boy's a liar Pt. 2\" by PinkPantheress...\n",
      "Done.\n",
      "Searching for \"Kill Bill\" by SZA...\n",
      "Done.\n",
      "Searching for \"Escapism.\" by RAYE...\n",
      "Done.\n",
      "Searching for \"Creepin' (with The Weeknd & 21 Savage)\" by Metro Boomin...\n",
      "Done.\n",
      "Searching for \"Calm Down (with Selena Gomez)\" by Rema...\n",
      "Done.\n",
      "Searching for \"TQG\" by KAROL G...\n",
      "Done.\n",
      "Searching for \"As It Was\" by Harry Styles...\n",
      "Done.\n",
      "Searching for \"Players\" by Coi Leray...\n",
      "Done.\n",
      "Searching for \"CUFF IT\" by Beyoncé...\n",
      "Done.\n",
      "Searching for \"Anti-Hero\" by Taylor Swift...\n",
      "Done.\n",
      "Searching for \"golden hour\" by JVKE...\n",
      "Done.\n",
      "Searching for \"Shakira: Bzrp Music Sessions, Vol. 53\" by Bizarrap...\n",
      "Done.\n",
      "Searching for \"Unholy (feat. Kim Petras)\" by Sam Smith...\n",
      "Done.\n",
      "Searching for \"Just Wanna Rock\" by Lil Uzi Vert...\n",
      "Done.\n",
      "Searching for \"Love Again\" by The Kid LAROI...\n",
      "Done.\n",
      "Searching for \"Heaven\" by Niall Horan...\n",
      "Done.\n",
      "Searching for \"LET GO\" by Central Cee...\n",
      "Done.\n",
      "Searching for \"I'm Good (Blue)\" by David Guetta...\n",
      "Done.\n",
      "Searching for \"OMG\" by NewJeans...\n",
      "Done.\n",
      "Searching for \"Snooze\" by SZA...\n",
      "Done.\n",
      "Searching for \"Here With Me\" by d4vd...\n",
      "Done.\n",
      "Searching for \"10:35\" by Tiësto...\n",
      "Done.\n",
      "Searching for \"Made You Look\" by Meghan Trainor...\n",
      "Done.\n",
      "Searching for \"I Ain't Worried\" by OneRepublic...\n",
      "Done.\n",
      "Searching for \"People\" by Libianca...\n",
      "Done.\n",
      "Searching for \"ceilings\" by Lizzy McAlpine...\n",
      "Done.\n",
      "Searching for \"I Like You (A Happier Song) (with Doja Cat)\" by Post Malone...\n",
      "Done.\n",
      "Searching for \"Miss You\" by Oliver Tree...\n",
      "Done.\n",
      "Searching for \"STAR WALKIN' (League of Legends Worlds Anthem)\" by Lil Nas X...\n",
      "Done.\n",
      "Searching for \"Until I Found You (with Em Beihold) - Em Beihold Version\" by Stephen Sanchez...\n",
      "No results found for: 'Until I Found You (with Em Beihold) - Em Beihold Version Stephen Sanchez'\n",
      "Searching for \"I'm Not Here To Make Friends\" by Sam Smith...\n",
      "Done.\n",
      "Searching for \"Late Night Talking\" by Harry Styles...\n",
      "Done.\n",
      "Searching for \"Lavender Haze\" by Taylor Swift...\n",
      "Done.\n",
      "Searching for \"Nobody Gets Me\" by SZA...\n",
      "Done.\n",
      "Searching for \"Rich Flex\" by Drake...\n",
      "Done.\n",
      "Searching for \"THE LONELIEST\" by Måneskin...\n",
      "Done.\n",
      "Searching for \"Bad Habit\" by Steve Lacy...\n",
      "Done.\n",
      "Searching for \"Last Night\" by Morgan Wallen...\n",
      "Done.\n",
      "Searching for \"Nonsense\" by Sabrina Carpenter...\n",
      "Done.\n",
      "Searching for \"La Bachata\" by Manuel Turizo...\n",
      "Done.\n",
      "Searching for \"Bones\" by Imagine Dragons...\n",
      "Done.\n",
      "Searching for \"Something in the Orange\" by Zach Bryan...\n",
      "Done.\n",
      "Searching for \"Rush\" by Ayra Starr...\n",
      "Done.\n",
      "Searching for \"About Damn Time\" by Lizzo...\n",
      "Done.\n",
      "Searching for \"Yandel 150\" by Yandel...\n",
      "Done.\n",
      "Searching for \"Vegas (From the Original Motion Picture Soundtrack ELVIS)\" by Doja Cat...\n",
      "Done.\n",
      "Searching for \"Superhero (Heroes & Villains) [with Future & Chris Brown]\" by Metro Boomin...\n",
      "Done.\n",
      "Searching for \"Tití Me Preguntó\" by Bad Bunny...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "track_items_dict = cred.get_lyrics ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_items_dict = cred.track_sentiment ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(track_items_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Song ID</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Die For You - Remix</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>78</td>\n",
       "      <td>7oDd86yk8itslrA9HRP2ki</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.525</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>0.502</td>\n",
       "      <td>66.900</td>\n",
       "      <td>TranslationsEspañolItalianoDeutschDie For You ...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.9982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>100</td>\n",
       "      <td>0yLdNVWF3Srea0uzk55zFn</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.325</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.646</td>\n",
       "      <td>117.999</td>\n",
       "      <td>TranslationsEspañolPortuguêsKiswahiliDeutschIt...</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boy's a liar Pt. 2</td>\n",
       "      <td>PinkPantheress</td>\n",
       "      <td>91</td>\n",
       "      <td>6AQbmUe0Qwf5PZnt4HmTXv</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.809</td>\n",
       "      <td>5</td>\n",
       "      <td>-8.254</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.2520</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>0.857</td>\n",
       "      <td>132.962</td>\n",
       "      <td>TranslationsPortuguêsTürkçeBoy’s a liar Pt. 2 ...</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>92</td>\n",
       "      <td>1Qrg8KqiBpW07V7PNxwwwL</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.735</td>\n",
       "      <td>8</td>\n",
       "      <td>-5.747</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0521</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.418</td>\n",
       "      <td>88.980</td>\n",
       "      <td>TranslationsEspañolPortuguêsItalianoTürkçeDeut...</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.6321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Escapism.</td>\n",
       "      <td>RAYE</td>\n",
       "      <td>89</td>\n",
       "      <td>5Z2MiIZ5I3jJvvmeWMLbOQ</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.742</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.355</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.250</td>\n",
       "      <td>96.107</td>\n",
       "      <td>TranslationsTürkçeEspañolPortuguêsEscapism. Ly...</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.7889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name          Artist  Popularity                 Song ID  \\\n",
       "0  Die For You - Remix      The Weeknd          78  7oDd86yk8itslrA9HRP2ki   \n",
       "1              Flowers     Miley Cyrus         100  0yLdNVWF3Srea0uzk55zFn   \n",
       "2   Boy's a liar Pt. 2  PinkPantheress          91  6AQbmUe0Qwf5PZnt4HmTXv   \n",
       "3            Kill Bill             SZA          92  1Qrg8KqiBpW07V7PNxwwwL   \n",
       "4            Escapism.            RAYE          89  5Z2MiIZ5I3jJvvmeWMLbOQ   \n",
       "\n",
       "   Danceability  Energy  Key  Loudness  Mode  Speechiness  Acousticness  \\\n",
       "0         0.531   0.525    1    -6.500     0       0.0671        0.2320   \n",
       "1         0.707   0.681    0    -4.325     1       0.0668        0.0632   \n",
       "2         0.696   0.809    5    -8.254     1       0.0500        0.2520   \n",
       "3         0.644   0.735    8    -5.747     1       0.0391        0.0521   \n",
       "4         0.538   0.742    2    -5.355     1       0.1140        0.1380   \n",
       "\n",
       "   Instrumentalness  Liveness  Valence    Tempo  \\\n",
       "0          0.000000    0.4410    0.502   66.900   \n",
       "1          0.000005    0.0322    0.646  117.999   \n",
       "2          0.000128    0.2480    0.857  132.962   \n",
       "3          0.144000    0.1610    0.418   88.980   \n",
       "4          0.000047    0.0934    0.250   96.107   \n",
       "\n",
       "                                              Lyrics  Positive  Neutral  \\\n",
       "0  TranslationsEspañolItalianoDeutschDie For You ...     0.125    0.625   \n",
       "1  TranslationsEspañolPortuguêsKiswahiliDeutschIt...     0.517    0.439   \n",
       "2  TranslationsPortuguêsTürkçeBoy’s a liar Pt. 2 ...     0.195    0.681   \n",
       "3  TranslationsEspañolPortuguêsItalianoTürkçeDeut...     0.203    0.609   \n",
       "4  TranslationsTürkçeEspañolPortuguêsEscapism. Ly...     0.083    0.823   \n",
       "\n",
       "   Negative  Compound  \n",
       "0     0.250   -0.9982  \n",
       "1     0.044    0.9998  \n",
       "2     0.124    0.9664  \n",
       "3     0.188    0.6321  \n",
       "4     0.095   -0.7889  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric_test = track_items_dict['Lyrics'][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = simple_preprocess(lyric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = corpora.Dictionary([words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word_dict.doc2bow(words)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus, num_topics=10, id2word=word_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic: 0</th>\n",
       "      <th>Topic: 1</th>\n",
       "      <th>Topic: 2</th>\n",
       "      <th>Topic: 3</th>\n",
       "      <th>Topic: 4</th>\n",
       "      <th>Topic: 5</th>\n",
       "      <th>Topic: 6</th>\n",
       "      <th>Topic: 7</th>\n",
       "      <th>Topic: 8</th>\n",
       "      <th>Topic: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do</td>\n",
       "      <td>do</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>do</td>\n",
       "      <td>do</td>\n",
       "      <td>the</td>\n",
       "      <td>do</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>do</td>\n",
       "      <td>do</td>\n",
       "      <td>the</td>\n",
       "      <td>and</td>\n",
       "      <td>do</td>\n",
       "      <td>one</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how</td>\n",
       "      <td>and</td>\n",
       "      <td>do</td>\n",
       "      <td>can</td>\n",
       "      <td>how</td>\n",
       "      <td>can</td>\n",
       "      <td>can</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>can</td>\n",
       "      <td>one</td>\n",
       "      <td>main</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>the</td>\n",
       "      <td>can</td>\n",
       "      <td>can</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>main</td>\n",
       "      <td>how</td>\n",
       "      <td>main</td>\n",
       "      <td>when</td>\n",
       "      <td>with</td>\n",
       "      <td>one</td>\n",
       "      <td>how</td>\n",
       "      <td>just</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>one</td>\n",
       "      <td>when</td>\n",
       "      <td>like</td>\n",
       "      <td>can</td>\n",
       "      <td>main</td>\n",
       "      <td>one</td>\n",
       "      <td>how</td>\n",
       "      <td>how</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>with</td>\n",
       "      <td>just</td>\n",
       "      <td>can</td>\n",
       "      <td>how</td>\n",
       "      <td>main</td>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "      <td>like</td>\n",
       "      <td>when</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>like</td>\n",
       "      <td>when</td>\n",
       "      <td>like</td>\n",
       "      <td>the</td>\n",
       "      <td>one</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>one</td>\n",
       "      <td>the</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nobody</td>\n",
       "      <td>like</td>\n",
       "      <td>just</td>\n",
       "      <td>with</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>lose</td>\n",
       "      <td>main</td>\n",
       "      <td>with</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic: 0 Topic: 1 Topic: 2 Topic: 3 Topic: 4 Topic: 5 Topic: 6 Topic: 7  \\\n",
       "0      you      you      you      you      you      you      you      you   \n",
       "1       do       do      and      and      the       do       do      the   \n",
       "2      can      the      the       do       do      the      and       do   \n",
       "3      how      and       do      can      how      can      can      and   \n",
       "4      the      can      one     main      and      and      the      can   \n",
       "5     main      how     main     when     with      one      how     just   \n",
       "6      and      one     when     like      can     main      one      how   \n",
       "7     with     just      can      how     main     when     when     like   \n",
       "8     like     when     like      the      one     with     with      one   \n",
       "9   nobody     like     just     with     like     like     lose     main   \n",
       "\n",
       "  Topic: 8 Topic: 9  \n",
       "0      you      you  \n",
       "1       do       do  \n",
       "2      one      the  \n",
       "3      and      can  \n",
       "4      can     just  \n",
       "5     like     like  \n",
       "6      how      how  \n",
       "7     when      and  \n",
       "8      the     with  \n",
       "9     with      one  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rand_dict = {}\n",
    "\n",
    "for idx, topic in lda_model.show_topics(num_topics=10, formatted=False):\n",
    "    rand_dict[f'Topic: {idx}'] = [word[0] for word in topic]\n",
    "\n",
    "    #print(f\"Topic: {idx} \\nWords: {[word[0] for word in topic]}\")\n",
    "\n",
    "df = pd.DataFrame(rand_dict)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of topics and the top n keywords for each topic\n",
    "NUM_TOPICS = 10\n",
    "NUM_KEYWORDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the text from each column into a single list of documents\n",
    "documents = []\n",
    "for column in df.columns:\n",
    "    documents += df[column].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the documents into a bag-of-words representation using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "doc_term_matrix = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform LDA topic modeling on the document-term matrix\n",
    "model = LatentDirichletAllocation(n_components=NUM_TOPICS, random_state=0)\n",
    "model.fit(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top keywords for each topic\n",
    "vocab = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "topics = []\n",
    "for i in range(NUM_TOPICS):\n",
    "    topic_keywords = model.components_[i].argsort()[::-1][:NUM_KEYWORDS]\n",
    "    keywords = [vocab[word] for word in topic_keywords]\n",
    "    topics.append(\" \".join(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Use KeyBERT to generate labels for each topic based on the top keywords\n",
    "model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "labels = model.extract_keywords(topics, keyphrase_ngram_range=(1, 3), stop_words='english', use_mmr=True, diversity=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Print the labels for each topic\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(labels):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTopic \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the labels for each topic\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Topic {i+1}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Song lyrics emotions:\n",
    "# Note that the emotional content of a text can be highly dependent on factors such as tone, style, and intended audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrclex import NRCLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gerardrius/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gerardrius/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: jinja2 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: setuptools in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (61.2.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gerardrius/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import gensim\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Download spaCy resources\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the song lyrics\n",
    "#with open('lyrics.txt', 'r') as f:\n",
    "#    lyrics = f.read()\n",
    "lyrics = track_items_dict['Lyrics'][0]\n",
    "\n",
    "# Tokenize the lyrics\n",
    "tokens = nltk.word_tokenize(lyrics.lower())\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "tokens = [token for token in tokens if not token in stop_words]\n",
    "\n",
    "# Remove punctuation\n",
    "tokens = [token for token in tokens if token.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theme of the song is: would\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary from the tokenized lyrics\n",
    "dictionary = gensim.corpora.Dictionary([tokens])\n",
    "\n",
    "# Convert the tokenized lyrics into a bag-of-words representation\n",
    "bow_corpus = [dictionary.doc2bow(tokens)]\n",
    "\n",
    "# Train an LDA model on the bag-of-words representation\n",
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=bow_corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Extract the main topic from the LDA model\n",
    "# Extract the main topic from the LDA model\n",
    "topic = lda_model.print_topics()[0][1]\n",
    "\n",
    "# Split the topic into individual words with proportions\n",
    "topic_words = topic.split('+')\n",
    "\n",
    "# Extract the word with the highest proportion\n",
    "representative_word = max(topic_words, key=lambda x: float(x.split('*')[0])) \\\n",
    "                      .split('*')[1].strip('\" ')\n",
    "\n",
    "# Print the representative word\n",
    "print('The theme of the song is:', representative_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E010] Word vectors set to length 0. This may be because you don't have a model installed or loaded, or because your model doesn't include word vectors. For more info, see the docs:\nhttps://spacy.io/usage/models",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb Cell 49\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb#Y230sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m topic_words:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb#Y230sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     word \u001b[39m=\u001b[39m word\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39mstrip(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb#Y230sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     word_vector \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39;49mvocab[word]\u001b[39m.\u001b[39;49mvector\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb#Y230sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     topic_vector \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m word_vector\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gerardrius/Ironhack/projects/Project-IV/src/1-responses.ipynb#Y230sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m topic_vector \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(topic_words)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ironhack/lib/python3.9/site-packages/spacy/lexeme.pyx:158\u001b[0m, in \u001b[0;36mspacy.lexeme.Lexeme.vector.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E010] Word vectors set to length 0. This may be because you don't have a model installed or loaded, or because your model doesn't include word vectors. For more info, see the docs:\nhttps://spacy.io/usage/models"
     ]
    }
   ],
   "source": [
    "# Calculate the average vector for all the words in the topic\n",
    "topic_words = topic.split(\"+\")\n",
    "topic_vector = np.zeros((nlp.vocab.vectors.shape[1],), dtype=\"float32\")\n",
    "for word in topic_words:\n",
    "    word = word.split(\"*\")[1].strip().strip('\"')\n",
    "    word_vector = nlp.vocab[word].vector\n",
    "    topic_vector += word_vector\n",
    "topic_vector /= len(topic_words)\n",
    "\n",
    "# Find the word closest to the topic vector in the Word Embedding space\n",
    "representative_word = nlp.vocab.vectors.most_similar(\n",
    "    topic_vector.reshape(1, -1), n=1\n",
    ")[0][0]\n",
    "\n",
    "# Print the representative word\n",
    "print('The theme of the song is:', representative_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[</th>\n",
       "      <th>1.</th>\n",
       "      <th>0.</th>\n",
       "      <th>0..1</th>\n",
       "      <th>0..2</th>\n",
       "      <th>0..3</th>\n",
       "      <th>0..4</th>\n",
       "      <th>0.]</th>\n",
       "      <th>During the period of falling in love, each time that we met and especially when we had not met for a long time.</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.]</td>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.]</td>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.]</td>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.]</td>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.]</td>\n",
       "      <td>When I did not speak the truth.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.]</td>\n",
       "      <td>Two years back someone invited me to be the tu...</td>\n",
       "      <td>seco</td>\n",
       "      <td>d</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.]</td>\n",
       "      <td>I had taken the responsibility to do something...</td>\n",
       "      <td>ent a</td>\n",
       "      <td>d</td>\n",
       "      <td>elt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.]</td>\n",
       "      <td>I was at home and I heard a loud sound of spit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.]</td>\n",
       "      <td>I did not do the homework that the teacher had...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7478</th>\n",
       "      <td>[</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.]</td>\n",
       "      <td>I had shouted at my younger brother and he was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7479 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      [   1.   0.  0..1  0..2  0..3  0..4  0.]  \\\n",
       "0     [  0.0  1.0   0.0   0.0   0.0   0.0  0.]   \n",
       "1     [  0.0  0.0   1.0   0.0   0.0   0.0  0.]   \n",
       "2     [  0.0  0.0   0.0   1.0   0.0   0.0  0.]   \n",
       "3     [  0.0  0.0   0.0   0.0   1.0   0.0  0.]   \n",
       "4     [  0.0  0.0   0.0   0.0   0.0   1.0  0.]   \n",
       "...  ..  ...  ...   ...   ...   ...   ...  ...   \n",
       "7474  [  0.0  0.0   1.0   0.0   0.0   0.0  0.]   \n",
       "7475  [  0.0  0.0   0.0   1.0   0.0   0.0  0.]   \n",
       "7476  [  0.0  0.0   0.0   0.0   1.0   0.0  0.]   \n",
       "7477  [  0.0  0.0   0.0   0.0   0.0   1.0  0.]   \n",
       "7478  [  0.0  0.0   0.0   0.0   0.0   0.0  1.]   \n",
       "\n",
       "     During the period of falling in love, each time that we met and especially when we had not met for a long time.  \\\n",
       "0            When I was involved in a traffic accident.                                                                \n",
       "1     When I was driving home after  several days of...                                                                \n",
       "2      When I lost the person who meant the most to me.                                                                \n",
       "3     The time I knocked a deer down - the sight of ...                                                                \n",
       "4                       When I did not speak the truth.                                                                \n",
       "...                                                 ...                                                                \n",
       "7474  Two years back someone invited me to be the tu...                                                                \n",
       "7475  I had taken the responsibility to do something...                                                                \n",
       "7476  I was at home and I heard a loud sound of spit...                                                                \n",
       "7477  I did not do the homework that the teacher had...                                                                \n",
       "7478  I had shouted at my younger brother and he was...                                                                \n",
       "\n",
       "     Unnamed: 9 Unnamed: 10 Unnamed: 11  \n",
       "0           NaN         NaN         NaN  \n",
       "1           NaN         NaN         NaN  \n",
       "2           NaN         NaN         NaN  \n",
       "3           NaN         NaN         NaN  \n",
       "4           NaN         NaN         NaN  \n",
       "...         ...         ...         ...  \n",
       "7474       seco           d         ear  \n",
       "7475      ent a           d         elt  \n",
       "7476        NaN         NaN         NaN  \n",
       "7477        NaN         NaN         NaN  \n",
       "7478        NaN         NaN         NaN  \n",
       "\n",
       "[7479 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_fwf('../data/text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spotifyToken ():\n",
    "    \"\"\"This function refreshes a token for a given app on Spotify\n",
    "    returns: token as a string\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Defining: credentials for the app\n",
    "    client_id = os.getenv(\"id\")\n",
    "    client_secret = os.getenv(\"secret\")\n",
    "    \n",
    "    #2. Request\n",
    "    body_params = {\"grant_type\":\"client_credentials\"}\n",
    "    url = \"https://accounts.spotify.com/api/token\"\n",
    "    response = requests.post(url, data=body_params, auth=(client_id,client_secret))\n",
    "    \n",
    "    try:\n",
    "        token = response.json()[\"access_token\"]\n",
    "        return token\n",
    "\n",
    "    except:\n",
    "        print(\"The request did not go through: wrong credentials!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genius token generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token():\n",
    "    client_id = os.getenv('genius_id')\n",
    "    client_secret = os.getenv('genius_key')\n",
    "\n",
    "    url = 'https://api.genius.com/oauth/token'\n",
    "    data = {\n",
    "        'client_id': client_id,\n",
    "        'client_secret': client_secret,\n",
    "        'grant_type': 'client_credentials'\n",
    "    }\n",
    "    response = requests.post(url, data=data)\n",
    "    if response.ok:\n",
    "        genius_token = response.json()['access_token']\n",
    "        return genius_token\n",
    "    else:\n",
    "        raise ValueError('Failed to get access token from Genius API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Authorization: Bearer 12345"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79e8e12960902be9b96136e06f35e6a59d5d8c359e0492f5e08d8a671bbdf383"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
